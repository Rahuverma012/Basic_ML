{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "**1. Explain the concept of linear regression and its key components.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zIcKQ0gCWzql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The linear regression model consists of a  predictor variable and a dependent variable related linearly to each  other. We try to ﬁnd the relationship between independent variable  (input) and a corresponding dependent variable (output).\n",
        "\n",
        "\n",
        "This can be expressed in the form of a straight line\n",
        "\n",
        "y = mx + c\n",
        "\n",
        "where -\n",
        "\n",
        "y => dependent variable\n",
        "\n",
        "x => independent variable\n",
        "\n",
        "m => slope of the line\n",
        "\n",
        "c => intercept\n",
        "\n",
        "=> Linear regression is also known as ordinary least squares (OLS) and\n",
        "linear least squares.\n",
        "\n",
        "=> The goal of linear regression is to create a  trend line or best ﬁt line based on the past  data.\n",
        "\n",
        "=> The best ﬁt line is considered to be the line for which the error between  the predicted values and the observed values is minimum. It is also called the regression line and the errors are also known as  residuals.\n",
        "\n"
      ],
      "metadata": {
        "id": "wqTpdRVnXNh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. How does gradient descent work in the context of linear regression?**\n",
        "\n"
      ],
      "metadata": {
        "id": "FrDijCmsW2PR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The primary goal of any Gradient descent to  minimize the Cost Function.\n",
        "\n",
        "The role of gradient descent is to provide direction and the  velocity (learning rate) of the movement in  order to attain the minima of the function i.e  where the cost is minimum\n",
        "\n",
        "**Cost Function** => The function which is used to  minimize for\n",
        "linear regression model i.e, mean squared error\n",
        "\n",
        "=> Minimizing cost  functions will also result in a lower error between the predicted values  and the actual values which also denotes that the algorithm has  performed well in learning.\n"
      ],
      "metadata": {
        "id": "MsAbVMSQYEfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. What are the assumptions of a regression line in linear regression?**\n",
        "\n"
      ],
      "metadata": {
        "id": "-mOMSigpW3yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assumption of regression line -\n",
        "\n",
        "=> The relation between the dependent and independent variables  should be almost linear.\n",
        "\n",
        "=> There should be homoscedasticity or equal variance in a regression  model.\n",
        "\n",
        "=> Error shouldn't be related to each other\n",
        "\n",
        "=> All observation should be independent\n",
        "\n",
        "=> There should not be multicollinearity in regression model.  \n"
      ],
      "metadata": {
        "id": "UH1TeRAZZRfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Define homoscedasticity and discuss its importance in linear regression.**\n",
        "\n"
      ],
      "metadata": {
        "id": "x1WDRPqcW5L6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Homoscedasticity (meaning “same variance”) describes a situation in  which the error term is the same across all values of the independent  variables.\n",
        "\n",
        "There are certain adavantages of having Homoscedasticity in the data such as -\n",
        "\n",
        "=>  Homoscedasticity leads to more reliable predictions\n",
        "\n",
        "=>  Homoscedasticity ensures that parameter estimates are accurate and are better representative.\n",
        "\n",
        "=> As the spread of the residuals remains consistent across different levels of the predictors, therefore model with homoscedastic residuals is more interpretable."
      ],
      "metadata": {
        "id": "rg4zPuusZrKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. What is multicollinearity? How does it affect the regression model?**\n",
        "\n"
      ],
      "metadata": {
        "id": "dHVBcWcyW6bE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multicollinearity occurs when independent variables in a regression  model are correlated.\n",
        "\n",
        "\n",
        "This correlation is a problem because independent variables should be  independent. If the degree of correlation between variables is high  enough, it can cause problems when you ﬁt the model and interpret the  results. Also due to the high correlation between variables, it becomes challenging to determine the unique contribution of each predictor to the model.\n",
        "\n",
        "\n",
        "**Variance inﬂation factor(VIF)** detects multicollinearity.\n",
        "\n",
        "A rule of thumb for interpreting the variance inﬂation factor:  \n",
        "\n",
        "1 = not correlated.\n",
        "\n",
        "Between 1 and 5 = moderately correlated.  \n",
        "\n",
        "Greater than 5 = highly correlated.\n"
      ],
      "metadata": {
        "id": "TZtRnWgYbVJE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Describe the properties of the regression line in linear regression.**\n",
        "\n"
      ],
      "metadata": {
        "id": "yZOaFd82W7pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> The regression line is the best-fit line that minimizes the sum of squared differences between observed and predicted values\n",
        "\n",
        "=> y = mx + c\n",
        "\n",
        "y => dependent variable\n",
        "\n",
        "x => independent variable\n",
        "\n",
        "m => slope of the line\n",
        "\n",
        "c => intercept\n",
        "\n",
        "=> The regression line represents a linear relationship between the independent variable and the dependent variable\n",
        "\n",
        "=> The intercept is the value of the dependent variable when the independent variable is zero\n",
        "\n",
        "=> The slope quantifies the change in the dependent variable for a one-unit change in the independent variable\n",
        "\n",
        "=> Residuals are the vertical distances between data points and the regression line, indicating the model's goodness of fit"
      ],
      "metadata": {
        "id": "j-1HNWrJctjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. What are the advantages of using linear regression as a machine learning algorithm?**\n",
        "\n"
      ],
      "metadata": {
        "id": "H7uPQJ1LW841"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Easy to Interpret the output.\n",
        "\n",
        "=> Easy to understand the algorith or the model.\n",
        "\n",
        "=> When variables are linearlly related then it gives good result.\n",
        "\n",
        "=> No hyperparameter tuning required.\n",
        "\n",
        "=> Can be applied of various problem statement.\n"
      ],
      "metadata": {
        "id": "C8ksJUKNdWND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Discuss the limitations of linear regression as a predictive modeling technique.**\n",
        "\n"
      ],
      "metadata": {
        "id": "44NtHrX9W-VE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=> Further optimization is very limited because of no hyperparameters.\n",
        "\n",
        "=> Performs well for those data only where variables are linearlly related.\n",
        "\n",
        "=> There are certain assumption for the model, which might not find a perfect fit when it comes to real world data.\n",
        "\n",
        "=> The model is sensitive to outliers.\n",
        "\n",
        "=> Multicollinearity issue."
      ],
      "metadata": {
        "id": "CtuWgrLieBkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Explain the meaning and purpose of various regression model evaluation metrics such as MSE, RMSE, MAE, R-squared, and adjusted R-squared.**\n",
        "\n"
      ],
      "metadata": {
        "id": "hFBioLLcW_ub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MSE** => It measures the average of the squared differences between the actual values and the predicted values\n",
        "\n",
        "**RMSE** => It is the square root of the MSE. It is easier to interpret than MSE because it is in the original units of the data.\n",
        "\n",
        "**MAE** => It measures the average absolute differences between actual and predicted values. It is less sensitive to outliers than MSE.\n",
        "\n",
        "**R-squared** => It is a measure of the proportion of the variance in the dependent variable that is explained by the independent variables in the model. It ranges from 0 to 1, with higher values indicating a better fit.\n",
        "\n",
        "**Adjusted R-squared** => It is a modified version of R-squared. It adjusts R-squared for the degrees of freedom, providing a more realistic measure of model fit"
      ],
      "metadata": {
        "id": "eYT89NK0e21E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Suppose you have a dataset with multiple independent variables and a continuous dependent variable. Which evaluation metric would you use to assess the performance of your linear regression model? Justify your choice.**"
      ],
      "metadata": {
        "id": "4I1Osw46XBCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to estimate the model I will be using multiple metrices such as -\n",
        "\n",
        "RMSE => Because it is easier to interpret than MSE and also it is in the original units of the data.\n",
        "\n",
        "MAE => Since it is less sensitive to outliers than MSE. So, it will be good estimate given that my dataset is having outliers. If no, then MSE can also be used.\n",
        "\n",
        "Adjusted R-squared => Since it provides a more realistic measure of model fit so I will be chhosing this one insted of simple R-squared value."
      ],
      "metadata": {
        "id": "zkXVoSaYgQE5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgYjcWNpWylH"
      },
      "outputs": [],
      "source": []
    }
  ]
}