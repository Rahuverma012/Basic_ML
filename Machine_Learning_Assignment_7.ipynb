{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Explain the concept of linear regression and its purpose in machine learning.**\n",
        "\n"
      ],
      "metadata": {
        "id": "i0zJOjpU1sdw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        " Linear regression is a fundamental supervised machine learning algorithm used to establish a predictive relationship between a dependent variable and one or more independent variables.\n",
        "\n",
        " Its primary purpose is to enable the prediction of the dependent variable's value based on observations of the independent variables, accomplished by fitting a linear equation to the data."
      ],
      "metadata": {
        "id": "aRpX07XW2aPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. What are the assumptions of linear regression?**\n",
        "\n"
      ],
      "metadata": {
        "id": "9Ng5E3LA1uUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assumptions of linear regression**\n",
        "\n",
        "**Linearity:** It assumes that the relationship between the dependent and independent variables is linear\n",
        "\n",
        "**Independence of Errors:** This assumption suggests that the differences between observed and predicted values are independent of each other.\n",
        "\n",
        "**Homoscedasticity:** Linear regression assumes that the variance of residuals is constant across all levels of the independent variables.\n",
        "\n",
        "**Normality of Errors:** The algorithm assumes that the residuals conform to a normal distribution."
      ],
      "metadata": {
        "id": "PbeDVy7O2n-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Discuss the difference between simple linear regression and multiple linear regression.**\n",
        "\n"
      ],
      "metadata": {
        "id": "i_n_EQaP1vy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple linear regression involves one independent variable, while multiple linear regression involves two or more independent variables.\n",
        "\n",
        "The main difference is the number of predictors used to model the dependent variable. Simple linear regression has one predictor, while multiple linear regression has multiple predictors."
      ],
      "metadata": {
        "id": "Ik5rPa1i2qoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. State two advantages and two disadvantages of linear regression.**\n",
        "\n"
      ],
      "metadata": {
        "id": "RHefqjbc1w_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advantages**\n",
        "\n",
        "Simplicity\n",
        "\n",
        "Interpretability\n",
        "\n",
        "**Disadvantages**\n",
        "\n",
        "Sensitive to outliers\n",
        "\n",
        "Assumption of linearity, which may not hold in all cases."
      ],
      "metadata": {
        "id": "yONvhbXx2sqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Define naive Bayes algorithm and explain how it works.**\n",
        "\n"
      ],
      "metadata": {
        "id": "LeGlBFdF1yKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The naive Bayes algorithm is a classification technique based on Bayes' theorem. It works by calculating the probability of a data point belonging to each class and assigning it to the class with the highest probability."
      ],
      "metadata": {
        "id": "kB0IyT7o2wgk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. What is the underlying assumption behind the naive Bayes algorithm?**\n",
        "\n"
      ],
      "metadata": {
        "id": "t5mAbwOV1zZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The underlying assumption behind the naive Bayes algorithm is the independence of features. It assumes that the features used to classify data points are conditionally independent, which may not always hold in real-world data."
      ],
      "metadata": {
        "id": "wptpvrXw2y0_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. What are the advantages and disadvantages of the naive Bayes algorithm?**\n",
        "\n"
      ],
      "metadata": {
        "id": "vPDb1nf9103T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advantages:**\n",
        "\n",
        "Simplicity\n",
        "\n",
        "Efficiency\n",
        "\n",
        "Effectiveness\n",
        "\n",
        "**Disadvantages:**\n",
        "\n",
        "Its performance may be compromised when the assumption of feature independence does not hold, leading to suboptimal results."
      ],
      "metadata": {
        "id": "5KMk1zOV20tR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Explain the concept of random forest and how it works.**\n",
        "\n"
      ],
      "metadata": {
        "id": "lM7xcLxe12m0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest is an ensemble learning method that combines multiple decision trees to make predictions. It works by aggregating the predictions of individual trees to improve accuracy and reduce overfitting."
      ],
      "metadata": {
        "id": "ocmV-Eby22tF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. How does random forest handle overfitting?**\n",
        "\n"
      ],
      "metadata": {
        "id": "S4yoZcRz13nG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Random forest addresses overfitting through two key strategies.**\n",
        "\n",
        " It employs bootstrapped samples of the data for training individual decision trees.\n",
        "\n",
        " It introduces randomness by selecting a subset of features when creating each tree. By combining the predictions of multiple trees, random forest effectively reduces the risk of overfitting."
      ],
      "metadata": {
        "id": "AfQ09Dj024rK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. State two advantages and two disadvantages of random forest.**\n",
        "\n"
      ],
      "metadata": {
        "id": "EacGEqg914hs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advantages:**\n",
        "\n",
        "Random forest is acclaimed for its high prediction accuracy and robustness, making it suitable for noisy data.\n",
        "\n",
        "It can handle both classification and regression tasks effectively.\n",
        "\n",
        "**Disadvantages:**\n",
        "\n",
        "Random forest models can become complex due to the ensemble nature\n",
        "\n",
        "Interpretation can be  challenging."
      ],
      "metadata": {
        "id": "vuN4R3rO26Tg"
      }
    }
  ]
}